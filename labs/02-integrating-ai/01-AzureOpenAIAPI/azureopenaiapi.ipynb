{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Working with the Azure OpenAI API directly\n",
    "\n",
    "In this lab, we will perform a couple of simple calls to the Azure OpenAI API.\n",
    "- The first call will allow us to find out which Model Deployments are available for the Azure OpenAI API.\n",
    "- The second call will send a prompt to the Azure OpenAI API.\n",
    "\n",
    "This will also prove that everything is setup correctly and working for the rest of the labs.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, we need to retrieve values from the `.env` file which we will use to make calls to the Azure OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found OpenAI API Base Endpoint: https://genaishowcase.openai.azure.com/\n",
      "1ec7612a1d3a43caa3daccf7fb5c5559\n",
      "2023-03-15-preview\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found OpenAI API Base Endpoint: \" + os.getenv(\"OPENAI_API_BASE\"))\n",
    "else: \n",
    "    print(\"OpenAI API Base Endpoint not found. Have you configured the .env file?\")\n",
    "    \n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# This version of the API is needed to properly retrieve the list of model deployments.\n",
    "API_VERSION = \"2023-03-15-preview\"\n",
    "print(API_VERSION)\n",
    "RESOURCE_ENDPOINT = os.getenv(\"OPENAI_API_BASE\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll set the endpoint that we're going to call. This endpoint will return a list of available model deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://genaishowcase.openai.azure.com//openai/deployments?api-version=2023-05-15\n"
     ]
    }
   ],
   "source": [
    "url = RESOURCE_ENDPOINT + \"/openai/deployments?api-version=\" + API_VERSION\n",
    "\n",
    "print (url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you will see the full URL that we are going to be calling."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of available Model Deployments\n",
    "\n",
    "Now let's call that Azure OpenAI endpoint and see what it returns. We pass the API key in the HTTP header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error\":{\"code\":\"404\",\"message\": \"Resource not found\"}}\n"
     ]
    }
   ],
   "source": [
    "#this works only if you are going to use the AD, does NOT work with AzureAD\n",
    "r = requests.get(url, headers={\"api-key\": API_KEY})\n",
    "\n",
    "\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, there should now be a JSON formatted list of model deployments. The output will contain one or more sections similar to the following\n",
    "\n",
    "```\n",
    "    {\n",
    "      \"scale_settings\": {\n",
    "        \"scale_type\": \"standard\"\n",
    "      },\n",
    "      \"model\": \"gpt-35-turbo\",\n",
    "      \"owner\": \"organization-owner\",\n",
    "      \"id\": \"gpt35turbo\",\n",
    "      \"status\": \"succeeded\",\n",
    "      \"created_at\": 1684150536,\n",
    "      \"updated_at\": 1684150536,\n",
    "      \"object\": \"deployment\"\n",
    "    }\n",
    "```\n",
    "\n",
    "In the output, you'll see the **Model Name** as the `model` value and the **Deployment Name** as the `id` value. We'll be using an `id` value for the next section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a prompt to Azure OpenAI using the API\n",
    "\n",
    "Next, let's call the Azure OpenAI API with a prompt. To do this, we'll need the `id` of our completion model deployment.\n",
    "\n",
    "We've already setup this value in the `.env` file, but you should see a matching value in the list that was output above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab API Version in the .env file.\n",
    "API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "DEPLOYMENT_ID = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we'll construct a URL to call. This time, we'll also be creating a payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://genaishowcase.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15\n"
     ]
    }
   ],
   "source": [
    "url = RESOURCE_ENDPOINT + \"/openai/deployments/\" + DEPLOYMENT_ID + \"/chat/completions?api-version=\" + API_VERSION\n",
    "\n",
    "print(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you will see the full URL that we are going to call. This URL will use the specified deployment to call the **chat completions** API.\n",
    "\n",
    "Next, we will call the Azure OpenAI API using the URL above. Just like last time, we pass the API key in the HTTP header. We also send a JSON formatted body as part of the request which contains the *prompt* that we want to use to get a response from the OpenAI model. In this case, our prompt is \"Once upon a time\", which should cause the model to complete the prompt by generating a story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8LAIXp72r8v59dDZiWmdqWU44S8nH\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1700055165,\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"in a small village, there lived a young girl named Lily. She lived with her mother and father in a cozy cottage by the woods. Lily was a curious and adventurous girl who loved exploring the world around her.\\n\\nOne sunny morning, after finishing her chores, Lily decided to wander deeper into the woods than she had ever gone before. She followed a narrow path, amazed by the beauty of nature surrounding her. Birds chirped happily, and colorful butterflies danced in the air.\\n\\nAs Lily continued her journey, she came across a hidden clearing deep in the woods. In the middle of the clearing stood a majestic, ancient-looking tree with glowing pink leaves. She had never seen such a tree before and felt drawn to it.\\n\\nCuriosity getting the better of her, Lily approached the tree cautiously. She reached out to touch one of the glowing leaves, and as soon as her hand made contact, she felt a surge of energy coursing through her body. Suddenly, her whole world began to spin.\\n\\nWhen Lily regained her senses, she found herself in a magical kingdom filled with talking animals, fairies, and enchanted creatures. The sky was filled with vibrant colors, and everything seemed to sparkle. It was like stepping into a dream.\\n\\nAs she explored the kingdom, Lily came across a young deer named Oliver. Oliver was friendly and explained to Lily that the magical tree had transported her to this realm. He told her that the kingdom was ruled by an evil sorceress who had put a spell on the land, causing it to be trapped in eternal darkness.\\n\\nDetermined to help, Lily decided to embark on a quest to defeat the sorceress and restore light and happiness to the kingdom. Oliver became her loyal companion, guiding her through the dangerous forest and introducing her to other magical creatures who were also fighting against the sorceress.\\n\\nThrough their journey, Lily discovered her own hidden powers. She could communicate with animals, control plants, and had a unique ability to heal others. These abilities proved to be essential in their battle against the sorceress.\\n\\nAfter enduring countless challenges and facing various creatures under the sorceress's control, Lily and her friends finally confronted the evil sorceress in her enchanted castle. With courage, determination, and the power of friendship, they defeated her and lifted the spell from the kingdom.\\n\\nAs a sign of gratitude, the magical creatures crowned Lily as their queen. She ruled the kingdom with fairness and kindness, ensuring that the land remained a place of magic and harmony. The kingdom flourished under her rule, and Lily's adventures in the magical realm became legends told for generations.\\n\\nAnd so, Lily lived happily ever after, surrounded by the love and magic of the enchanted kingdom she had rescued. She cherished her memories from the woods and the extraordinary journey that had changed her life forever.\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 12,\n",
      "    \"completion_tokens\": 564,\n",
      "    \"total_tokens\": 576\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "r = requests.post(url, headers={\"api-key\": API_KEY}, json={\"messages\":[{\"role\": \"assistant\", \"content\": \"Once upon a time \"}]})\n",
    "\n",
    "print(json.dumps(r.json(), indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the result of the API call will be JSON data similar to the below example.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"id\": \"chatcmpl-7wVxE2LNxaY6ZoxcWAmhiyrqaLZgf\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"created\": 1694180212,\n",
    "  \"model\": \"gpt-35-turbo\",\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"index\": 0,\n",
    "      \"finish_reason\": \"stop\",\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \", there was a magical kingdom called Tildor ... )))\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"usage\": {\n",
    "    \"completion_tokens\": 366,\n",
    "    \"prompt_tokens\": 13,\n",
    "    \"total_tokens\": 379\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Here's some more information about some of the data contained in that response.\n",
    "\n",
    "Key | Description\n",
    "--- | ---\n",
    "`model` | The model that was used to generate the response to the prompt\n",
    "`content` | This is the response that was generated by the OpenAI model. Note that the response example above was edited to remove most of the output to make it easier to read\n",
    "`finish_reason` | This is the reason that the model stopped generating the response. In this case, `stop` indicates the model determined it had fully completed the response without hitting any limits\n",
    "`completion_tokens` | The number of tokens that were used in generating the response\n",
    "`prompt_tokens` | The number of tokens that were consumed by the prompt\n",
    "`total_tokens` | The total number of tokens that were consumed by the request (`prompt_tokens` + `completion_tokens`)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we used the Azure OpenAI API directly to query information about our instance of the Azure OpenAI service and to send a prompt to an OpenAI model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "In the next lab, we will look at using the OpenAI SDK to work with the Azure OpenAI service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Section\n",
    "\n",
    "ðŸ“£ [OpenAI Packages/Libraries](../02-OpenAIPackages/openai.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
