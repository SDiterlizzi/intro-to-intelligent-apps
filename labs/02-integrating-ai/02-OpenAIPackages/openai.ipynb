{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Using the OpenAI Library\n",
    "\n",
    "In the [first](../01-AzureOpenAIAPI/azureopenaiapi.ipynb) lab, we walked through calling the Azure OpenAI API directly to list available model deployments and submit a prompt for completion. An easier way to work with an API is to use a *Library*. A Library is a collection of packages and modules that allow reusable code to be shared with the community.\n",
    "\n",
    "In this lab, we'll use the OpenAI Python library to perform the same operations as we did in the first lab."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use the `import` statement to let our application know that we're going to be using the OpenAI library in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll bring in the values from our `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found OpenAI API Base Endpoint: https://genaishowcase.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found OpenAI API Base Endpoint: \" + os.getenv(\"OPENAI_API_BASE\"))\n",
    "else: \n",
    "    print(\"OpenAI API Base Endpoint not found. Have you configured the .env file?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenAI library needs some configuration parameters set to allow it to work with the OpenAI service. We'll set the following parameters.\n",
    "\n",
    "Parameter name | Description\n",
    "--- | ---\n",
    "`openai.api_type` | We set this value to indicate whether we're using the native OpenAI service, or the Azure OpenAI service\n",
    "`openai.api_key` | This is the value for our API key\n",
    "`openai.api_base` | This is the resource endpoint for the OpenAI service we're using\n",
    "`openai_api_version` | This is the version of the API we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "# This version of the API is needed to properly retrieve the list of model deployments.\n",
    "openai.api_version = \"2023-03-15-preview\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of available Model Deployments\n",
    "\n",
    "We can now call the `Deployment.list()` method of the OpenAI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x7f8e5882c290> JSON: {\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"scale_settings\": {\n",
       "        \"scale_type\": \"standard\"\n",
       "      },\n",
       "      \"model\": \"gpt-4\",\n",
       "      \"owner\": \"organization-owner\",\n",
       "      \"id\": \"GPT-4\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"created_at\": 1691361034,\n",
       "      \"updated_at\": 1698146894,\n",
       "      \"object\": \"deployment\"\n",
       "    },\n",
       "    {\n",
       "      \"scale_settings\": {\n",
       "        \"scale_type\": \"standard\"\n",
       "      },\n",
       "      \"model\": \"gpt-35-turbo-16k\",\n",
       "      \"owner\": \"organization-owner\",\n",
       "      \"id\": \"GPT-35\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"created_at\": 1698146875,\n",
       "      \"updated_at\": 1698146875,\n",
       "      \"object\": \"deployment\"\n",
       "    },\n",
       "    {\n",
       "      \"scale_settings\": {\n",
       "        \"scale_type\": \"standard\"\n",
       "      },\n",
       "      \"model\": \"gpt-4-32k\",\n",
       "      \"owner\": \"organization-owner\",\n",
       "      \"id\": \"GPT-4-32k\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"created_at\": 1698839813,\n",
       "      \"updated_at\": 1698839813,\n",
       "      \"object\": \"deployment\"\n",
       "    },\n",
       "    {\n",
       "      \"scale_settings\": {\n",
       "        \"scale_type\": \"standard\"\n",
       "      },\n",
       "      \"model\": \"gpt-35-turbo\",\n",
       "      \"owner\": \"organization-owner\",\n",
       "      \"id\": \"gpt-35-turbo\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"created_at\": 1700042024,\n",
       "      \"updated_at\": 1700042024,\n",
       "      \"object\": \"deployment\"\n",
       "    },\n",
       "    {\n",
       "      \"scale_settings\": {\n",
       "        \"scale_type\": \"standard\"\n",
       "      },\n",
       "      \"model\": \"text-embedding-ada-002\",\n",
       "      \"owner\": \"organization-owner\",\n",
       "      \"id\": \"text-embedding-ada-002\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"created_at\": 1700042297,\n",
       "      \"updated_at\": 1700042297,\n",
       "      \"object\": \"deployment\"\n",
       "    }\n",
       "  ],\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Deployment.list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see that the result is the same JSON data that we got when we called the API directly.\n",
    "\n",
    "## Send a prompt to Azure OpenAI using the OpenAI library\n",
    "\n",
    "Ok, now that we have the list of deployment models, let's try to do a Completion.\n",
    "\n",
    "We'll use the values from our `.env` file to configure this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab API Version in the .env file.\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "COMPLETION_MODEL = os.getenv(\"OPENAI_COMPLETION_MODEL\")\n",
    "DEPLOYMENT_ID = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've configured the OpenAI Python library in the previous steps, we can go ahead and call the completions method to generate a response. We'll call the `ChatCompletion.create()` method and pass in the name of our `model`, the `deployment_id` and the `prompt` we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8LAauyI9QLryUsqMMphX3mNsMQSWT\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1700056304,\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"spending time with my loved ones.\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 18,\n",
      "    \"completion_tokens\": 8,\n",
      "    \"total_tokens\": 26\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "r = openai.ChatCompletion.create(\n",
    "    model = COMPLETION_MODEL,\n",
    "    deployment_id = DEPLOYMENT_ID,\n",
    "    messages = [{\"role\" : \"assistant\", \"content\" : \"The one thing I love more than anything else is \"}],\n",
    ")\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the response above should be the same JSON data that we got when we called the API directly, containing details of the model we called, the response that was generated and the token usage.\n",
    "\n",
    "We could also just extract the generated response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spending time with my loved ones.\n"
     ]
    }
   ],
   "source": [
    "print(r.choices[0].message.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The OpenAI library provides a more concise way to work with the OpenAI API. Once we've set up the initial parameters, we don't need to send them each time as we need to do with a direct API call. It's also easier to add information such as prompts to the call, as we can pass those values in as part of the call to the OpenAI library methods instead of having to pass in JSON objects as part of the request body.\n",
    "\n",
    "You can find more details about the completions API in the reference documentation:\n",
    "\n",
    "https://platform.openai.com/docs/api-reference/completions/create"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "In the next lab we'll begin looking at AI orchestrators. Whereas the OpenAI library simplfies working with the OpenAI API, orchestrators take things to the next level!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Section\n",
    "\n",
    "📣 [Langchain](../03-Langchain/langchain.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
