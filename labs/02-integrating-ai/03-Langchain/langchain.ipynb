{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Langchain\n",
    "\n",
    "In this lab, we will introduce [Langchain](https://python.langchain.com/docs/get_started/introduction), a framework for developing applications powered by language models.\n",
    "\n",
    "Langchain supports Python and Javascript / Typescript. For this lab, we will use Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by importing the `AzureOpenAI` specific components from the `langchain` package, including models and schemas for interacting with the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with all the other labs, we'll need to provide our API key and endpoint details, so we'll load them from our `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found OpenAPI Base Endpoint: https://genaishowcase.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if load_dotenv():\n",
    "    print(\"Found OpenAPI Base Endpoint: \" + os.getenv(\"OPENAI_API_BASE\"))\n",
    "else: \n",
    "    print(\"No file .env found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll configure Langchain by providing the API key and endpoint details, along with the API version information.\n",
    "\n",
    "As Langchain can work with multiple AI services, we need to specify that we want to work with Azure via the `openai_api_type` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of Azure OpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_type = openai.api_type,\n",
    "    openai_api_version = os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    openai_api_base = os.getenv(\"OPENAI_API_BASE\"),\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a prompt to Azure OpenAI using Langchain\n",
    "\n",
    "We're now ready to send a request to Azure OpenAI. To do this, we invoke the `llm` instance we created above and pass in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the age of the President of the United States, you can follow these steps:\n",
      "\n",
      "1. Identify the current President: Find out who the current President of the United States is. As of September 2021, the President is Joe Biden.\n",
      "\n",
      "2. Determine the birthdate: Look up the birthdate of the President. Joe Biden was born on November 20, 1942.\n",
      "\n",
      "3. Calculate the current year: Determine the current year. Let's assume the current year is 2021.\n",
      "\n",
      "4. Subtract the birth year from the current year: Subtract the birth year of the President from the current year to find the age. In this case, subtract 1942 from 2021.\n",
      "\n",
      "   2021 - 1942 = 79\n",
      "\n",
      "5. Determine the President's age: The result of the subtraction will give you the age of the President. In this case, the President is 79 years old.\n",
      "\n",
      "So, as of September 2021, Joe Biden is 79 years old. Please note that this information may change over time as years pass and new Presidents are elected.\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt we want the AI to respond to - the message the Human user is asking\n",
    "msg = HumanMessage(content=\"Explain step by step. How old is the president of USA?\")\n",
    "\n",
    "# Call the API\n",
    "r = llm(messages=[msg])\n",
    "\n",
    "# Print the response\n",
    "print(r.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a prompt to Azure OpenAI using Langchain Chaining\n",
    "\n",
    "Now that we have seen Langchain in action, let's take a quick peek at chaining and adding variables to our prompt. To do this we will add `LLMChain` to the `llm` instance created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the OpenAI API, we still had to pass the prompt in using the `Completion.create()` method. With Langchain, we can create a `PromptTemplate`. This way, we can define our prompt up front and leave placeholders for values that will be set later on. The placeholder could be values that are passed from an end user or application via an API. We don't know what they at this point.\n",
    "\n",
    "In the below example, the `{input}` in curly brackets is the placeholder value that will be populated later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] template='What interesting things can I make with a {input}?'\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt template with variables, note the curly braces\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=\"What interesting things can I make with a {input}?\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a chain. In this case, the chain has two components. One component is the prompt template. The other is the object that represents our AI model (`llm`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we initiate the chain. You can see that we pass in a value for the `input` placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are numerous interesting projects you can create with a Raspberry Pi! Here are a few examples:\n",
      "\n",
      "1. Retro gaming console: Build your own retro gaming console using RetroPie, a software package for Raspberry Pi that allows you to emulate classic game consoles.\n",
      "\n",
      "2. Home automation system: Control and monitor your home appliances, lights, and security using a Raspberry Pi with platforms like Home Assistant or OpenHAB.\n",
      "\n",
      "3. Media center: Transform your Raspberry Pi into a media center using Kodi, allowing you to stream movies, TV shows, music, and more to your TV.\n",
      "\n",
      "4. Weather station: Gather weather data using sensors connected to your Raspberry Pi and display it on a web interface or an LCD screen.\n",
      "\n",
      "5. Smart mirror: Create a smart mirror that displays weather updates, calendar events, news headlines, and more while functioning as a regular mirror.\n",
      "\n",
      "6. Security camera: Set up a DIY security camera system by connecting a camera module to your Raspberry Pi and using motion detection software like MotionEyeOS.\n",
      "\n",
      "7. Pi-powered robot: Build a small robot using a Raspberry Pi as the brain, allowing you to control its movements, interact with sensors, and perform various tasks.\n",
      "\n",
      "8. Network-wide ad-blocker: Set up a network-wide ad-blocker using a Raspberry Pi and Pi-hole software, blocking ads on all devices connected to your network.\n",
      "\n",
      "9. Voice assistant: Create your own voice-controlled assistant using a Raspberry Pi, a microphone, and software like Google Assistant, Alexa, or Mycroft.\n",
      "\n",
      "10. Portable gaming console: Build a handheld gaming console using Raspberry Pi Zero or Raspberry Pi Compute Module, allowing you to play retro games on the go.\n",
      "\n",
      "These are just a few examples, and there are countless other projects you can explore with a Raspberry Pi. The possibilities are limited only by your imagination and creativity!\n"
     ]
    }
   ],
   "source": [
    "# Run the chain only specifying the input variable.\n",
    "response = chain.run({\"input\": \"raspberry pi\"})\n",
    "\n",
    "# As we are using a single input variable, you could also run the string like this:\n",
    "# response = chain.run(\"raspberry pi\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Langchain is an example of an AI orchestrator. It provides an alternative method to the raw API or using an SDK package to access the AI models, but on top of that can provide additional integrations, deal with issues related to rate limiting of the API and provide an abstraction layer over potentially complex operations. We'll get into those more complex use cases in later labs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "In the next lab, we'll look at another AI Orchestrator - Semantic Kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Section\n",
    "\n",
    "📣 [Semantic Kernel](../04-SemanticKernel/semantickernel.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
